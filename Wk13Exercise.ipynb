{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9f4f98",
   "metadata": {},
   "source": [
    "# Exercise 1: Identifying the Best-Performing Model\n",
    "We are giving you three different outputs from genre-prediction models. Your job is to use precision, recall, and F1 score metrics to determine which model has the best performance in predicting a movie's genre.\n",
    "\n",
    "Download each of three outputs from different genre-prediction tasks:\n",
    "File 1 from Model 1 Download File 1 from Model 1\n",
    "File 2 from Model 2 Download File 2 from Model 2\n",
    "File 3 from Model 3 Download File 3 from Model 3\n",
    "These files contain a row for every prediction, and each row contains the movie ID, predicted genre, the set of actual genres, and whether the prediction was correct (1 for correct, 0 for incorrect).\n",
    "\"Correct\" is 1 if the predicted genre exists in the set of actual genres.\n",
    "E.g., a row contains a prediction for \"Action\", and the \"actual genres\" column contains \"['Action', 'Adventure', 'Comedy']\", the row's prediction is correct since \"Action\" appears in the genre set.\n",
    "For each file, calculate accuracy, precision, recall, and F1 scores for each of the following genres separately:\n",
    "Drama\n",
    "Comedy\n",
    "Horror\n",
    "To determine precision/recall for a movie of a specific genre, \"negative\" samples are all movies where that genre does not appear in the \"actual genre\" column, and \"positive samples\" are all movies where that genre *does* appear in the \"actual genre\" column.\n",
    "Use these metrics to justify which model–models 1, 2, or 3–produces the best predictions.\n",
    "List of Genres (some of which will have zero predictions):\n",
    "\n",
    "['Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Biography',\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Family',\n",
    " 'Fantasy',\n",
    " 'History',\n",
    " 'Horror',\n",
    " 'Music',\n",
    " 'Musical',\n",
    " 'Mystery',\n",
    " 'News',\n",
    " 'Romance',\n",
    " 'Sci-Fi',\n",
    " 'Sport',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.8169761273209549},\n",
       " 'Adventure': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9135278514588859},\n",
       " 'Animation': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9697612732095491},\n",
       " 'Biography': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9607427055702917},\n",
       " 'Comedy': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.6870026525198939},\n",
       " 'Crime': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.8620689655172413},\n",
       " 'Documentary': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9681697612732095},\n",
       " 'Drama': {'precision': 0.4981432360742706,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6650141643059491,\n",
       "  'accuracy': 0.4981432360742706},\n",
       " 'Family': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9517241379310345},\n",
       " 'Fantasy': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9506631299734748},\n",
       " 'History': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9787798408488063},\n",
       " 'Horror': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.8440318302387267},\n",
       " 'Music': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9750663129973475},\n",
       " 'Musical': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9920424403183024},\n",
       " 'Mystery': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9220159151193634},\n",
       " 'News': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9984084880636604},\n",
       " 'Romance': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.8663129973474801},\n",
       " 'Sci-Fi': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9538461538461539},\n",
       " 'Sport': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9809018567639257},\n",
       " 'Thriller': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.7920424403183024},\n",
       " 'War': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9909814323607427},\n",
       " 'Western': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'accuracy': 0.9925729442970822}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('prediction_model_01.csv')\n",
    "df2 = pd.read_csv('prediction_model_02.csv')\n",
    "df3 = pd.read_csv('prediction_model_03.csv')\n",
    "\n",
    "\n",
    "def clean(df): # function for cleaning purposes to calculate scoring metrics afterwards\n",
    "    df = df.copy()\n",
    "    df['actual'] = df['actual genres'].apply(ast.literal_eval) # treat as list with copy\n",
    "    return df\n",
    "\n",
    "df1 = clean(df1)\n",
    "df2 = clean(df2)\n",
    "df3 = clean(df3)\n",
    "\n",
    "genres = ['Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Biography',\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Family',\n",
    " 'Fantasy',\n",
    " 'History',\n",
    " 'Horror',\n",
    " 'Music',\n",
    " 'Musical',\n",
    " 'Mystery',\n",
    " 'News',\n",
    " 'Romance',\n",
    " 'Sci-Fi',\n",
    " 'Sport',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Western']\n",
    "\n",
    "def compute_metrics(df):\n",
    "    results = {}\n",
    "    for g in genres:\n",
    "        g_true = df['actual'].apply(lambda lst: g in lst)\n",
    "        g_pred = df['predicted'] == g\n",
    "\n",
    "        precision = precision_score(g_true, g_pred, zero_division=0)\n",
    "        recall = recall_score(g_true, g_pred, zero_division=0)\n",
    "        f1 = f1_score(g_true, g_pred, zero_division=0)\n",
    "        accuracy = accuracy_score(g_true, g_pred)\n",
    "        results[g] = dict(precision=precision, recall=recall, f1=f1, accuracy=accuracy)\n",
    "    return results\n",
    "\n",
    "metrics1 = compute_metrics(df1)\n",
    "metrics2 = compute_metrics(df2)\n",
    "metrics3 = compute_metrics(df3)\n",
    "\n",
    "metrics1\n",
    "\n",
    "\n",
    "metrics2\n",
    "\n",
    "\n",
    "metrics3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
